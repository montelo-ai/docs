---
title: Quickstart
description: Let’s get you up and running with Montelo in under 2 minutes.
icon: play
---

## Sign up for Montelo

To get started, you need to first [sign up](https://app.montelo.ai/auth/register) for a **free** account.

## Installing the SDK

Start by installing Montelo.

```sh
npm install montelo
```

## API Keys

After setting up your account, you can find your API key for the environment you want to use from the dashboard.

<video
  muted
  autoPlay
  loop
  playsInline
  className="w-full aspect-video"
  src="/assets/apikey.mp4"
></video>

<Note>Each project has several environments, and each environment has it’s own API Key.</Note>

When developing in a team, it's a good idea to create a new environment for each developer.
This way, developers can work independently without interfering with each other's work.

With your API key in hand, you can now set up the SDK.
Either include the API key as an environment variable called `MONTELO_API_KEY` or pass it as an argument to the `Montelo` constructor.

```dotenv .env
MONTELO_API_KEY=your-api-key
OPENAI_API_KEY=your-openai-api-key
```

## Replace OpenAI/Anthropic/Mistral calls with Montelo

Now that you have the SDK set up, you can start using Montelo to collect production requests. First, simply replace
OpenAI/Anthropic/Mistral calls with Montelo, just by adding `montelo.` to the beginning of the call.

For example, to call OpenAI:

```typescript main.ts
import { Montelo } from "montelo";

const montelo = new Montelo();

await montelo.openai.chat.completions.create({
  model: "gpt-4",
  messages: [
    {
      role: "system",
      content: "You are a helpful assistant.",
    },
    {
      role: "user",
      content: "What is the meaning of life?",
    },
  ]
});
```

## Start a trace

To trace multiple logs together, create a new trace:

```typescript
const trace = montelo.trace({ name: "Sample Trace" });

await trace.anthropic.messages.create({
  name: "Action 1",
  model: "claude-3-sonnet-20240229",
  messages: [{ role: "user", content: "Tell me a joke about the person reading this." }],
  max_tokens: 100,
});

await trace.mistral.chat({
  name: "Action 2",
  model: "mistral-tiny",
  messages: [{ role: "user", content: "Tell me a joke about the person reading this." }],
});

await montelo.openai.chat.completions.create({
  name: "Action 3",
  model: "gpt-3.5-turbo",
  messages: [
    { role: "user", content: "Tell me a joke about the person reading this." },
  ],
});
```

<video
  muted
  autoPlay
  loop
  playsInline
  className="w-full aspect-video"
  src="/assets/trace.mp4"
></video>

## Create a dataset

Create a dataset via our SDK.

```typescript
const dataset = await montelo.datasets.create({
  name: "Sentiment analysis",
  description: "Sentiment analysis dataset for project X",
  inputSchema: { sentence: "string" },
  outputSchema: { sentiment: "string" },
});
```

## Upload datapoints

```typescript
await montelo.datapoints.createMany({
  dataset: dataset.slug,
  datapoints: [
    {
      input: { sentence: "That was an awesome event." },
      expectedOutput: { sentiment: "positive" }
    },
    {
      input: { sentence: "That was a bad event." },
      expectedOutput: { sentiment: "negative" }
    }
  ],
});
```

## Run an experiment

Now that you have an uploaded dataset, you can run an experiment against it!

You supply a runner and an evaluator function that runs against each datapoint in the dataset. What you return from
the runner and evaluator are then logged and tracked for you to analyze in Montelo.

```typescript
await montelo.experiments.createAndRun({
  name: "My First Experiment",
  description: "So exciting!",
  dataset: dataset.slug,
  runner: async ({ input, metadata }) => {
    const sentiment = await llmRequest(input, metadata);
    return { sentiment }
  },
  evaluator: async ({ input, expectedOutput, actualOutput, metadata }) => {
    return {
      isCorrect: expectedOutput.sentiment === actualOutput.sentiment,
    }
  },
});
```

## Next Steps

Check out our [blog posts](https://montelo.ai/blog) to learn more about:

- Classification using fine-tuned GPT-3.5 ([link](https://www.montelo.ai/blog/classification-using-fine-tuned-gpt3-5-in-typescript))
- Integrating with the Vercel AI SDK ([link](https://www.montelo.ai/blog/montelo-vercel-ai-sdk-v3-tutorial))
- View the code for complete examples in our `examples` [repo](https://github.com/montelo-org/examples)

