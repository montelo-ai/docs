---
title: Logs
description: Simple and flexible logging for your LLM applications.
icon: list-timeline
---

Each log contains information about an event that occurred in your application. This could be a user interaction, a model completion, or anything else you want to track.

Logs are independent and by default are not linked to any other logs. However, you can group logs together using [traces](/traces/traces).

## Basic

Logging is automatically handled for you when using the Montelo SDK.

```typescript
const montelo = new Montelo();

await montelo.openai.chat.completions.create({ ... });
```

That is all you need to do to get started with logging. The logs will be sent to the Montelo servers, and you can view them in the Montelo dashboard.

### Parameters

When Montelo overrides the LLM Provider's sdk, we add a few parameters that you need to include in your input.

This means you could log something like this:

```typescript
const montelo = new Montelo();

await montelo.openai.chat.completions.create({
  name: "Browse the web",
  model: "gpt-4",
  messages: [...],
  extra: {
    some: "extra data"
  },
});
```

## Manual

You can also manually log events using the `log` method.

```typescript
const montelo = new Montelo();

montelo.log({
  name: "Browse the web",
  input: { some: "input" },
  output: { some: "output" },
  // ...
});
```

